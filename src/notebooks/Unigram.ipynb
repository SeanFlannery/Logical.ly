{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import torch\n",
    "import spacy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize hyper hyper parameters\n",
    "torch.manual_seed(420)\n",
    "np.random.seed(420)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fallacies_df = pd.read_csv('../data/fallacies.csv', index_col=0)\n",
    "approved_df = pd.read_csv('../data/approved.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    fallacies_df,\n",
    "    approved_df[approved_df.n_supporters >= 5].drop(\"n_supporters\", axis=1)\n",
    "])\n",
    "df.fallacy_reason = df.fallacy_reason.fillna('')\n",
    "df = df[~df.premise_content.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = df.fallacy_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.fallacy_type.isin(vc.head(10).index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sent):\n",
    "    sent = sent.lower()\n",
    "    sent = nlp(sent)\n",
    "    words = map(lambda x: x.text, sent)\n",
    "    return list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['premise_content_preprocessed'] = df.premise_content.apply(preprocess_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=420).reset_index(drop=True) # shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.1, random_state=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vocab = {\"<oov>\", \"<pad>\"}\n",
    "word_vocab = word_vocab.union(\n",
    "    set(chain.from_iterable(map(lambda x: x[1][\"premise_content_preprocessed\"], train_df.iterrows())))\n",
    ")\n",
    "word_to_ix = {word: i for i, word in enumerate(word_vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fallacy_vocab = sorted(list(set(df.fallacy_type.unique())))\n",
    "fallacy_to_ix = {word: i for i, word in enumerate(fallacy_vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, word_vocab_size, word_embedding_dim, fallacy_vocab_size, max_sent_size):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding(\n",
    "            word_vocab_size, word_embedding_dim\n",
    "        )  # random init\n",
    "\n",
    "        hidden = 100\n",
    "        self.fc1 = nn.Linear(word_embedding_dim, hidden)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden * max_sent_size, fallacy_vocab_size)\n",
    "        \n",
    "    def forward(self, word_inputs):\n",
    "        word_embeds = self.word_embeddings(word_inputs)\n",
    "        h1 = self.fc1(word_embeds)\n",
    "        a1 = self.relu(h1)\n",
    "        h2 = self.fc2(a1.view(a1.shape[0], -1))\n",
    "        return h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_and_convert_to_ints(data):\n",
    "    X = np.full((len(data), MAX_SENT_SIZE), word_to_ix[\"<pad>\"])\n",
    "\n",
    "    for i, (_, x) in enumerate(data.iterrows()):\n",
    "        X[i, :len(x[\"premise_content_preprocessed\"])] = [\n",
    "            (word_to_ix[word] if word in word_to_ix else word_to_ix['<oov>'])\n",
    "            for word in x[\"premise_content_preprocessed\"]\n",
    "        ]\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = pad_and_convert_to_ints(train_df)\n",
    "testX = pad_and_convert_to_ints(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = train_df.fallacy_type.apply(lambda x: fallacy_to_ix[x]).values\n",
    "testY = test_df.fallacy_type.apply(lambda x: fallacy_to_ix[x]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(\n",
    "    len(word_vocab),\n",
    "    300,\n",
    "    len(fallacy_vocab),\n",
    "    MAX_SENT_SIZE,\n",
    ")\n",
    "opt = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(X, Y, model, opt, criterion, batch_size=50):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for beg_i in range(0, X.shape[0], batch_size):\n",
    "        x_batch = X[beg_i : beg_i + batch_size, :]\n",
    "        y_batch = Y[beg_i : beg_i + batch_size]\n",
    "        x_batch = torch.tensor(x_batch)\n",
    "        y_batch = torch.tensor(y_batch)\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        y_pred = model(x_batch)\n",
    "\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        opt.step()\n",
    "\n",
    "        losses.append(loss.data.numpy())\n",
    "\n",
    "    return [sum(losses) / float(len(losses))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:57<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "e_losses = []\n",
    "num_epochs = 50\n",
    "for e in tqdm(range(num_epochs)):\n",
    "    e_losses += train_epoch(trainX, trainY, net, opt, criterion, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.648647062918719,\n",
       " 1.1579338803010828,\n",
       " 0.8639095863875221,\n",
       " 0.6519683020956376,\n",
       " 0.49754232957082634,\n",
       " 0.3916252329945564,\n",
       " 0.3144337480120799,\n",
       " 0.26024389179313884,\n",
       " 0.22472450838369482,\n",
       " 0.2021918112740797,\n",
       " 0.1836471551043146,\n",
       " 0.16652311954428167,\n",
       " 0.15389170563396284,\n",
       " 0.15304387185503454,\n",
       " 0.1436967558282263,\n",
       " 0.14165554579128237,\n",
       " 0.13380510666791132,\n",
       " 0.13742583508000655,\n",
       " 0.12878754932214231,\n",
       " 0.12868005935760105,\n",
       " 0.12467504183159155,\n",
       " 0.12622744973529787,\n",
       " 0.11861445009708405,\n",
       " 0.1246930636903819,\n",
       " 0.11598835775957388,\n",
       " 0.12288909931393231,\n",
       " 0.11224004746798207,\n",
       " 0.1150429095415508,\n",
       " 0.10807052999734879,\n",
       " 0.11504645579878021,\n",
       " 0.10653888543739039,\n",
       " 0.11149197751108338,\n",
       " 0.10753859864438281,\n",
       " 0.11131234160240959,\n",
       " 0.10827652616974186,\n",
       " 0.11072050692404017,\n",
       " 0.10511275315109421,\n",
       " 0.10995837542064049,\n",
       " 0.10358512478277963,\n",
       " 0.10620599875555319,\n",
       " 0.10325937071705565,\n",
       " 0.1080795708386337,\n",
       " 0.09915090396123774,\n",
       " 0.10312960121561499,\n",
       " 0.0985911726294195,\n",
       " 0.10133734082474428,\n",
       " 0.0978328839820974,\n",
       " 0.10259808994391385,\n",
       " 0.09564990605063298,\n",
       " 0.10024470178519979]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics (macro f1 score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    x = torch.tensor(testX)\n",
    "    y_pred = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "score = f1_score(testY, y_pred.numpy().argmax(axis=1), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19663854875283446"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guessing Appeal To Authority\t for all:\t0.004347826086956523\n",
      "Guessing Appeal To Belief\t for all:\t0.0064516129032258064\n",
      "Guessing Begging The Question\t for all:\t0.005405405405405406\n",
      "Guessing Fallacy Of False Cause\t for all:\t0.00851063829787234\n",
      "Guessing Fallacy Of Red Herring\t for all:\t0.005405405405405406\n",
      "Guessing Irrelevant Conclusion\t for all:\t0.02178217821782178\n",
      "Guessing None\t for all:\t0.07959866220735787\n",
      "Guessing Poisoning The Well\t for all:\t0.0011049723756906078\n",
      "Guessing Prejudicial Language\t for all:\t0.003278688524590164\n",
      "Guessing Wrong Direction\t for all:\t0.0074866310160427805\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"Guessing \" + fallacy_vocab[i] + \"\\t for all:\", end='\\t')\n",
    "    print(f1_score(testY, np.array( [i]*testY.shape[0]), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Guessing:\t0.05702413272128415\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Guessing:\", end='\\t')\n",
    "print(f1_score(testY, np.random.randint(0,10,testY.shape[0]), average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
