{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import spacy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "fallacies_df = pd.read_csv('../data/fallacies.csv', index_col=0)\n",
    "approved_df = pd.read_csv('../data/approved.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.fallacy_reason = df.fallacy_reason.fillna('')\n",
    "\n",
    "df = pd.concat([\n",
    "    fallacies_df,\n",
    "    approved_df[approved_df.n_supporters >= 5].drop(\"n_supporters\", axis=1)\n",
    "])\n",
    "\n",
    "df = df[~df.premise_content.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = df.fallacy_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.fallacy_type.isin(vc.head(10).index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sent):\n",
    "    sent = sent.lower()\n",
    "    sent = nlp(sent)\n",
    "    words = map(lambda x: x.text, sent)\n",
    "    return list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['premise_content_preprocessed'] = df.premise_content.apply(preprocess_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True) # shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vocab = {\"<oov>\", \"<pad>\"}\n",
    "word_vocab = word_vocab.union(\n",
    "    set(chain.from_iterable(map(lambda x: x[1][\"premise_content_preprocessed\"], train_df.iterrows())))\n",
    ")\n",
    "word_to_ix = {word: i for i, word in enumerate(word_vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "fallacy_vocab = set(df.fallacy_type.unique())\n",
    "fallacy_to_ix = {word: i for i, word in enumerate(fallacy_vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, word_vocab_size, word_embedding_dim, fallacy_vocab_size):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding(\n",
    "            word_vocab_size, word_embedding_dim\n",
    "        )  # random init\n",
    "\n",
    "        hidden = 100\n",
    "        self.fc1 = nn.Linear(word_embedding_dim, hidden)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden, fallacy_vocab_size)\n",
    "        \n",
    "    def forward(self, word_inputs):\n",
    "        word_embeds = self.word_embeddings(word_inputs)\n",
    "        h1 = self.fc1(word_embeds)\n",
    "        a1 = self.relu(h1)\n",
    "        h2 = self.fc2(a1)\n",
    "        return h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_and_convert_to_ints(data):\n",
    "    max_size = len(\n",
    "        max(data.iterrows(),\n",
    "            key=lambda x: len(x[1][\"premise_content_preprocessed\"]))[1]\n",
    "        [\"premise_content_preprocessed\"])\n",
    "    X = np.full((len(data), max_size), word_to_ix[\"<pad>\"])\n",
    "\n",
    "    for i, (_, x) in enumerate(data.iterrows()):\n",
    "        X[i, :len(x[\"premise_content_preprocessed\"])] = [\n",
    "            (word_to_ix[word] if word in word_to_ix else word_to_ix['<oov>'])\n",
    "            for word in x[\"premise_content_preprocessed\"]\n",
    "        ]\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = pad_and_convert_to_ints(train_df)\n",
    "testX = pad_and_convert_to_ints(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = train_df.fallacy_type.apply(lambda x: fallacy_to_ix[x]).values\n",
    "testY = test_df.fallacy_type.apply(lambda x: fallacy_to_ix[x]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(\n",
    "    len(word_vocab),\n",
    "    10,\n",
    "    len(fallacy_vocab)\n",
    ")\n",
    "opt = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(X, Y, model, opt, criterion, batch_size=50):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for beg_i in range(0, X.shape[0], batch_size):\n",
    "        x_batch = X[beg_i : beg_i + batch_size, :]\n",
    "        y_batch = Y[beg_i : beg_i + batch_size]\n",
    "        x_batch = torch.tensor(x_batch)\n",
    "        \n",
    "        y_onehot = (np.arange(len(fallacy_vocab)) == y_batch[:,None]).astype(np.long)\n",
    "        y_onehot = torch.from_numpy(y_onehot)\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        y_pred = model(x_batch)\n",
    "\n",
    "        loss = criterion(y_pred, y_onehot)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        opt.step()\n",
    "\n",
    "        losses.append(loss.data.numpy())\n",
    "\n",
    "    return [sum(losses) / float(len(losses))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:58<00:00,  1.72it/s]\n"
     ]
    }
   ],
   "source": [
    "e_losses = []\n",
    "num_epochs = 100\n",
    "for e in tqdm(range(num_epochs)):\n",
    "    e_losses += train_epoch(trainX, trainY, net, opt, criterion, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.079296280356014,\n",
       " 3.612408203237197,\n",
       " 3.250465883928187,\n",
       " 3.0295575787039364,\n",
       " 2.897688262602862,\n",
       " 2.8013391775243424,\n",
       " 2.7209101845236385,\n",
       " 2.650587558746338,\n",
       " 2.5873507331399357,\n",
       " 2.530113556805779,\n",
       " 2.4774994569666244,\n",
       " 2.42874215630924,\n",
       " 2.3832123700310204,\n",
       " 2.340719741933486,\n",
       " 2.3008682938183056,\n",
       " 2.2635538928649006,\n",
       " 2.228869957082412,\n",
       " 2.196645673583536,\n",
       " 2.1667637264027313,\n",
       " 2.1389953879749073,\n",
       " 2.113375250030966,\n",
       " 2.0897367000579834,\n",
       " 2.0678575599894806,\n",
       " 2.0475393744076,\n",
       " 2.0284380141426537,\n",
       " 2.0104459664400887,\n",
       " 1.9934797216864193,\n",
       " 1.977383487364825,\n",
       " 1.9620820985120886,\n",
       " 1.9475790051852955,\n",
       " 1.9336818737142227,\n",
       " 1.9203567645129036,\n",
       " 1.9074766355402328,\n",
       " 1.8950139073764576,\n",
       " 1.8830180168151855,\n",
       " 1.8714232444763184,\n",
       " 1.8601855320089005,\n",
       " 1.8493060364442713,\n",
       " 1.8387943436117733,\n",
       " 1.8285879457698149,\n",
       " 1.8187457954182344,\n",
       " 1.8092001816805672,\n",
       " 1.7999028808930342,\n",
       " 1.7908845017938053,\n",
       " 1.7821017223245956,\n",
       " 1.7735902351491593,\n",
       " 1.7653251816244686,\n",
       " 1.7573269114774817,\n",
       " 1.7495783918044145,\n",
       " 1.742047485183267,\n",
       " 1.7347384410745956,\n",
       " 1.7276457478018368,\n",
       " 1.7207586064058191,\n",
       " 1.7140515201232012,\n",
       " 1.7075427209629732,\n",
       " 1.7012140189900118,\n",
       " 1.6950766900006462,\n",
       " 1.6891178664039164,\n",
       " 1.6833331935545977,\n",
       " 1.6777116480995626,\n",
       " 1.6722624372033512,\n",
       " 1.6669397213879753,\n",
       " 1.6617482269511503,\n",
       " 1.6567092713187723,\n",
       " 1.6517770150128532,\n",
       " 1.6470025427201216,\n",
       " 1.642310941920561,\n",
       " 1.6377537601134355,\n",
       " 1.6333107527564554,\n",
       " 1.6289940441355986,\n",
       " 1.6247699541204117,\n",
       " 1.6206411333645092,\n",
       " 1.6166227635215311,\n",
       " 1.6127040877061731,\n",
       " 1.6088926161036772,\n",
       " 1.6051711054409252,\n",
       " 1.6015406706753899,\n",
       " 1.5980112272150375,\n",
       " 1.5945621448404648,\n",
       " 1.5911864883759443,\n",
       " 1.5878987031824447,\n",
       " 1.584680522189421,\n",
       " 1.5815429617376888,\n",
       " 1.578487333129434,\n",
       " 1.5755003971212052,\n",
       " 1.5726048315272612,\n",
       " 1.569776177406311,\n",
       " 1.566995852133807,\n",
       " 1.5642834060332353,\n",
       " 1.561663873055402,\n",
       " 1.55909166616552,\n",
       " 1.5565948766820572,\n",
       " 1.554118457962485,\n",
       " 1.5517131581025965,\n",
       " 1.5493786825853235,\n",
       " 1.547091056318844,\n",
       " 1.5448495219735539,\n",
       " 1.5426695066339828,\n",
       " 1.540551459088045,\n",
       " 1.5384636205785416]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
